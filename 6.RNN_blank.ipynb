{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kimhantag/Posco_AIBigdata_Academy25_edu/blob/main/6.RNN_blank.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d22e9c3",
      "metadata": {
        "id": "7d22e9c3"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import random\n",
        "import re\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "random.seed(1)\n",
        "np.random.seed(1)\n",
        "tf.random.set_seed(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a99fefd",
      "metadata": {
        "id": "5a99fefd",
        "outputId": "aed6d273-3811-4d17-b4a4-bf4ae268d395",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17464789/17464789 [==============================] - 0s 0us/step\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "(25000,)\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "top_words = 10000\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=top_words) #  데이터로드에 정해진 parameter로서, 할당된 크기만큼 자주쓰인 단어를 불러옴\n",
        "\n",
        "print(x_train.shape) # list가 총 25,000개 있음, 이 리뷰안에 여러 단어가 쓰였을텐데 위에서 언급한 10000개의 단어만 사용하게 됩니다.\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)  # 0과 1이 있다. 0의 경우 부정 , 1의 경우 긍정\n",
        "print(y_test[0]) # 0 이 나온 것으로 미루어 부정적인 리뷰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89c42f1f",
      "metadata": {
        "id": "89c42f1f",
        "outputId": "55233d6c-281b-4439-9efe-ffbdf75ce37f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1641221/1641221 [==============================] - 0s 0us/step\n",
            "the\n",
            "and\n",
            "a\n",
            "of\n",
            "to\n",
            "direct\n",
            "[Example] lengths of 5 reviews:  [218, 189, 141, 550, 147]\n",
            "The longest length of the review : 2494\n",
            "The average length of the review : 238.71364\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "word_to_index = tf.keras.datasets.imdb.get_word_index()\n",
        "\n",
        "index_to_word ={}\n",
        "for key, value in word_to_index.items():    # dictionary 를 tuple들로 만들기\n",
        "    index_to_word[value + 3] = key          # value+3가 단어가 사용된 순위, key가 단어입니다. +3을 해주는 이유는 0,1,2가 special로 설정되었기 때문에, 3이 제일 많이 나온 단어이기 때문입니다.\n",
        "\n",
        "for i in range(5) :\n",
        "    print(index_to_word[i + 4])  ## 제일 많이 나온 단어 5개  / 다섯번째를 불러오는게 아니라 키 값에 맞는 value를 불러오는 것임.\n",
        "\n",
        "print(index_to_word[1504]) # 1500번째로 잘 많이 나온 단어\n",
        "\n",
        "len_result = [len(s) for s in x_train] # 길이의 값을 list로 만듦\n",
        "print('[Example] lengths of 5 reviews: ', len_result[:5])\n",
        "print('The longest length of the review : {}'.format(np.max(len_result)))\n",
        "print('The average length of the review : {}'.format(np.mean(len_result)))\n",
        "\n",
        "plt.subplot(2,2,2)\n",
        "plt.hist(len_result, bins=50)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f56b0df",
      "metadata": {
        "id": "0f56b0df",
        "outputId": "2f7cc84a-0c74-4393-ee21-2b484bb5a23f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]\n",
            "<sos> this has to be one of the worst films of the 1990s when my friends i were watching this film being the target audience it was aimed at we just sat watched the first half an hour with our jaws touching the floor at how bad it really was the rest of the time everyone else in the theatre just started talking to each other leaving or generally crying into their popcorn that they actually paid money they had <unk> working to watch this feeble excuse for a film it must have looked like a great idea on paper but on film it looks like no one in the film has a clue what is going on crap acting crap costumes i can't get across how <unk> this is to watch save yourself an hour a bit of your life\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")): # pad 패드토큰=단어 | sos 시작을 알리는 토큰 | unk 주어진 단어가 미확인이라고 하는 토큰\n",
        "    index_to_word[index]=token\n",
        "print(x_train[2])\n",
        "print(' '.join([index_to_word[index] for index in x_train[2]]))\n",
        "print(y_train[2]) # 어떤 리뷰인지 맞춰보기 0은 부정 1은 긍정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2b55074d",
      "metadata": {
        "id": "2b55074d"
      },
      "outputs": [],
      "source": [
        "# truncate and pad input sequences with .preprocessing.sequence.pad_sequences\n",
        "max_len = 200  # 이 길이보다 sequence의 길이가 자르면 잘라낼 것이고, 짧다면 의미없는 값을 집어넣어(padding 과정:0으로 집어넣음) sequence의 길이를 200으로 맞추어 줍니다.\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=200) # 200보다 짧을 경우 0으로 padding하는 코드\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "318d3aa5",
      "metadata": {
        "id": "318d3aa5"
      },
      "outputs": [],
      "source": [
        "es = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', mode ='min', verbose = 1, patience=3)\n",
        "mc1 = tf.keras.callbacks.ModelCheckpoint('./rnn_imdb', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)\n",
        "mc2 = tf.keras.callbacks.ModelCheckpoint('./lstm_imdb', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)\n",
        "mc3 = tf.keras.callbacks.ModelCheckpoint('./multi_imdb', monitor = 'val_accuracy', mode = 'max', verbose = 1, save_best_only = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c441a82c",
      "metadata": {
        "id": "c441a82c",
        "outputId": "6edd3798-a850-4258-e386-d8988c2c0202",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 160)         1600000   \n",
            "                                                                 \n",
            " simple_rnn (SimpleRNN)      (None, 64)                14400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1614465 (6.16 MB)\n",
            "Trainable params: 1614465 (6.16 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "rnn = tf.keras.Sequential()\n",
        "# (1, 255, 1999 ~~~) 단어를 숫자로 매핑 1~10000\n",
        "rnn.add(layers.Embedding(top_words, 160)) # 1 -> R^160 각각의 인덱스로 표현된 단어들을 벡터로 표현\n",
        "# [batch_size, 200, 1] -> [batch_size, 200, 160]\n",
        "# x:input, h:hidden | h_new = xw_x + hw_h + b | b -> 64dim | w_x -> 160*64 dim | w_h -> 64*64 dim\n",
        "rnn.add(layers.SimpleRNN(64)) # -> 64:hidden states dimension\n",
        "rnn.add(layers.Dense(1, activation = 'sigmoid'))\n",
        "rnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a2cfcc8",
      "metadata": {
        "id": "5a2cfcc8",
        "outputId": "50bbf893-c7ab-4144-94eb-6fad4b9f7dcd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "358/358 [==============================] - ETA: 0s - loss: 0.5436 - accuracy: 0.7085\n",
            "Epoch 1: val_accuracy improved from -inf to 0.81060, saving model to ./rnn_imdb\n",
            "358/358 [==============================] - 45s 120ms/step - loss: 0.5436 - accuracy: 0.7085 - val_loss: 0.4404 - val_accuracy: 0.8106\n",
            "Epoch 2/5\n",
            "358/358 [==============================] - ETA: 0s - loss: 0.3309 - accuracy: 0.8636\n",
            "Epoch 2: val_accuracy improved from 0.81060 to 0.84620, saving model to ./rnn_imdb\n",
            "358/358 [==============================] - 39s 108ms/step - loss: 0.3309 - accuracy: 0.8636 - val_loss: 0.4062 - val_accuracy: 0.8462\n",
            "Epoch 3/5\n",
            "358/358 [==============================] - ETA: 0s - loss: 0.2330 - accuracy: 0.9080\n",
            "Epoch 3: val_accuracy did not improve from 0.84620\n",
            "358/358 [==============================] - 38s 107ms/step - loss: 0.2330 - accuracy: 0.9080 - val_loss: 0.4698 - val_accuracy: 0.8322\n",
            "Epoch 4/5\n",
            "358/358 [==============================] - ETA: 0s - loss: 0.1204 - accuracy: 0.9584\n",
            "Epoch 4: val_accuracy did not improve from 0.84620\n",
            "358/358 [==============================] - 37s 105ms/step - loss: 0.1204 - accuracy: 0.9584 - val_loss: 0.5441 - val_accuracy: 0.8334\n",
            "Epoch 5/5\n",
            "358/358 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9771\n",
            "Epoch 5: val_accuracy did not improve from 0.84620\n",
            "358/358 [==============================] - 38s 105ms/step - loss: 0.0699 - accuracy: 0.9771 - val_loss: 0.7077 - val_accuracy: 0.7828\n",
            "Epoch 5: early stopping\n"
          ]
        }
      ],
      "source": [
        "rnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
        "result = rnn.fit(x_train, y_train, epochs = 5, callbacks=[es, mc1], batch_size = 64,\n",
        "                 validation_split = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe5f85c4",
      "metadata": {
        "id": "fe5f85c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef65cade-f04f-4e7e-e210-043e83fc1d30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 13s 17ms/step - loss: 0.7138 - accuracy: 0.7802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7138184309005737, 0.7801600098609924]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "rnn.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8798307a",
      "metadata": {
        "id": "8798307a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15521fa6-153a-4a7b-c0da-0d80ef255a10"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 14s 17ms/step - loss: 0.4198 - accuracy: 0.8409\n",
            "[0.4197905957698822, 0.8409199714660645]\n"
          ]
        }
      ],
      "source": [
        "loaded_model = tf.keras.models.load_model('rnn_imdb')\n",
        "print((loaded_model.evaluate(x_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f35dded5",
      "metadata": {
        "id": "f35dded5"
      },
      "outputs": [],
      "source": [
        "def sentiment_predict(new_sentence):\n",
        "    # 알파벳과 숫자를 제외하고 모두 제거 및 알파벳 소문자화\n",
        "    new_sentence = re.sub('[^0-9a-zA-Z ]', '', new_sentence).lower()\n",
        "\n",
        "    # 정수 인코딩\n",
        "    encoded = []\n",
        "    for word in new_sentence.split():\n",
        "        # 단어 집합의 크기를 10,000으로 제한.\n",
        "        try :\n",
        "            if word_to_index[word] <= 10000:\n",
        "                encoded.append(word_to_index[word]+3)\n",
        "            else:\n",
        "                # 10,000 이상의 숫자는 <unk> 토큰으로 취급.\n",
        "                encoded.append(2)\n",
        "        # 단어 집합에 없는 단어는 <unk> 토큰으로 취급.\n",
        "        except KeyError:\n",
        "            encoded.append(2)\n",
        "\n",
        "    pad_new = tf.keras.preprocessing.sequence.pad_sequences([encoded], maxlen = max_len) # 패딩\n",
        "    score = float(loaded_model.predict(pad_new)) # 예측\n",
        "    if(score > 0.5):\n",
        "        print(\"positive with the probability {:.2f}% .\".format(score * 100))\n",
        "    else:\n",
        "        print(\"negative with the probability {:.2f}% \".format((1 - score) * 100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b81d41c6",
      "metadata": {
        "id": "b81d41c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d96672d-8ebe-4b2f-e465-a183d505f1bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 195ms/step\n",
            "negative with the probability 91.14% \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-0be091181bb0>:20: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  score = float(loaded_model.predict(pad_new)) # 예측\n"
          ]
        }
      ],
      "source": [
        "My_review = \"hi this movie is the amazing movie i have ever seen in my life. really intersting very fun. This was what I thought before the end of the movie. The last scene was really disgusting\"\n",
        "sentiment_predict(My_review)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c79d2065",
      "metadata": {
        "id": "c79d2065",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111f2013-9395-441c-d5b7-3b4cb4d110d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, None, 160)         1600000   \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                57600     \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1657730 (6.32 MB)\n",
            "Trainable params: 1657730 (6.32 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "lstm = tf.keras.Sequential()\n",
        "lstm.add(layers.Embedding(top_words, 160))\n",
        "lstm.add(layers.LSTM(64))\n",
        "lstm.add(layers.Dense(2, activation='softmax'))\n",
        "lstm.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9e6c864",
      "metadata": {
        "id": "c9e6c864",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17646cdb-4edb-401a-e11f-1c93588defb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train LSTM Model With \n",
            "Epoch 1/5\n",
            "334/334 [==============================] - ETA: 0s - loss: 0.4209 - accuracy: 0.8019\n",
            "Epoch 1: val_accuracy improved from -inf to 0.87100, saving model to ./lstm_imdb\n",
            "334/334 [==============================] - 149s 441ms/step - loss: 0.4209 - accuracy: 0.8019 - val_loss: 0.3158 - val_accuracy: 0.8710\n",
            "Epoch 2/5\n",
            "334/334 [==============================] - ETA: 0s - loss: 0.2375 - accuracy: 0.9077\n",
            "Epoch 2: val_accuracy did not improve from 0.87100\n",
            "334/334 [==============================] - 138s 412ms/step - loss: 0.2375 - accuracy: 0.9077 - val_loss: 0.3551 - val_accuracy: 0.8640\n",
            "Epoch 3/5\n",
            "334/334 [==============================] - ETA: 0s - loss: 0.1636 - accuracy: 0.9396\n",
            "Epoch 3: val_accuracy did not improve from 0.87100\n",
            "334/334 [==============================] - 100s 299ms/step - loss: 0.1636 - accuracy: 0.9396 - val_loss: 0.3988 - val_accuracy: 0.8622\n",
            "Epoch 4/5\n",
            "334/334 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9614\n",
            "Epoch 4: val_accuracy did not improve from 0.87100\n",
            "334/334 [==============================] - 103s 309ms/step - loss: 0.1108 - accuracy: 0.9614 - val_loss: 0.4185 - val_accuracy: 0.8560\n",
            "Epoch 4: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d663e621b10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "lstm.compile(optimizer='adam', loss = 'sparse_categorical_crossentropy', metrics =['accuracy'])\n",
        "print(\"Train LSTM Model With \")\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size = 0.2, random_state = 1, stratify = y_train)\n",
        "\n",
        "lstm.fit(x_train, y_train, epochs=5, callbacks = [es,mc2], batch_size= 60, validation_data=(x_val, y_val) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f637288",
      "metadata": {
        "id": "0f637288",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07be3a99-1938-4040-bed4-c119c4199900"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 15s 19ms/step - loss: 0.7138 - accuracy: 0.7802\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7138184309005737, 0.7801600098609924]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "rnn.evaluate(x_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d811269",
      "metadata": {
        "id": "7d811269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7bccc42-a085-4dcf-a14a-16648479db52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 34s 43ms/step - loss: 0.3263 - accuracy: 0.8614\n",
            "[0.3262588381767273, 0.8613600134849548]\n"
          ]
        }
      ],
      "source": [
        "loaded_model2 = tf.keras.models.load_model('lstm_imdb')\n",
        "print((loaded_model2.evaluate(x_test, y_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a236484",
      "metadata": {
        "id": "5a236484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "159fbf79-c9d4-48b9-b464-dbc2602fc8d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Multi_LSTM\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "You must compile your model before training/testing. Use `model.compile(optimizer, loss)`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-742d268da3b8>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train Multi_LSTM\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmulti_lstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\"fill here\"\"\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   3981\u001b[0m         \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3983\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   3984\u001b[0m                 \u001b[0;34m\"You must compile your model before \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3985\u001b[0m                 \u001b[0;34m\"training/testing. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ],
      "source": [
        "multi_lstm = tf.keras.Sequential()\n",
        "multi_lstm.add(layers.Embedding(top_words, 160))\n",
        "multi_lstm.add(layers.LSTM(64, return_sequences = True))\n",
        "multi_lstm.add(layers.LSTM(64))\n",
        "multi_lstm.add(layers.Dense(2, activation = 'softmax'))\n",
        "\n",
        "multi_lstm.complie(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
        "\n",
        "print(\"Train Multi_LSTM\")\n",
        "multi_lstm.fit(x_train, y_train, epochs=5, callbacks=[es, mc2], batch_size=60, validation_data=(x_val, y_val) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83120124",
      "metadata": {
        "id": "83120124"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}